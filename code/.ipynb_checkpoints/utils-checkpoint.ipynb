{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4975df42-4f24-492d-bd34-5bfa5f302489",
   "metadata": {},
   "source": [
    "This python file contains the functions for our final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fc4c2-cf2b-4709-a3d7-0e1619451fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c09cb-8ea3-40aa-ae4e-2b304dc3cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_philly_crime_data(years, base_path=\"data\", filename_template=\"philadelphia_crime_data_{}.csv\"):\n",
    "    \"\"\"\n",
    "    Loads and concatenates Philadelphia crime data across multiple years.\n",
    "\n",
    "    Parameters:\n",
    "        years (list): List of years to load (e.g. [2021, 2022, 2023])\n",
    "        base_path (str): Folder where files are stored\n",
    "        filename_template (str): Filename format with one {} placeholder for the year\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame of crime data with 'date' and 'year' columns\n",
    "    \"\"\"\n",
    "    crime_dfs = []\n",
    "\n",
    "    for year in years:\n",
    "        file_path = f\"{base_path}/{filename_template.format(year)}\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"year\"] = year\n",
    "        df[\"dispatch_date_time\"] = pd.to_datetime(df[\"dispatch_date_time\"])\n",
    "        df[\"date\"] = df[\"dispatch_date_time\"].dt.floor(\"D\")\n",
    "        crime_dfs.append(df)\n",
    "\n",
    "    return pd.concat(crime_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5aa25-9383-45ec-a322-68c30dc1e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chicago_crime_data(years, base_path=\"data\", filename_template=\"chicago_crime_data_{}.csv\"):\n",
    "    \"\"\"\n",
    "    Loads and concatenates Philadelphia crime data across multiple years.\n",
    "\n",
    "    Parameters:\n",
    "        years (list): List of years to load (e.g. [2021, 2022, 2023])\n",
    "        base_path (str): Folder where files are stored\n",
    "        filename_template (str): Filename format with one {} placeholder for the year\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame of crime data with 'date' and 'year' columns\n",
    "    \"\"\"\n",
    "    crime_dfs = []\n",
    "\n",
    "    for year in years:\n",
    "        file_path = f\"{base_path}/{filename_template.format(year)}\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"year\"] = year\n",
    "        df[\"dispatch_date_time\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df[\"date\"] = df[\"dispatch_date_time\"].dt.floor(\"D\")\n",
    "        df[\"lat\"]=df[\"Latitude\"]\n",
    "        df[\"lng\"]=df[\"Longitude\"]\n",
    "        crime_dfs.append(df)\n",
    "\n",
    "    return pd.concat(crime_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661dc9e7-03ea-4bb0-bded-278a0b4f2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfl_game_date(year, team):\n",
    "    # load the specific year\n",
    "    path_nfl = kagglehub.dataset_download(\"keonim/nfl-game-scores-dataset-2017-2023\")\n",
    "    df = pd.read_csv(f\"{path_nfl}/Season_Scores/{year}_scores.csv\")\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # subsets the df to games where the team is playing\n",
    "    df_away = df[(df[\"AwayTeam\"] == team)]\n",
    "    df_home = df[(df[\"HomeTeam\"] == team)]\n",
    "\n",
    "    home_dates_with_year = df_home['Date'].apply(\n",
    "        lambda x: f\"{x}/{year+1}\" if int(str(x).split('/')[0]) <= 6 \n",
    "        else f\"{x}/{year}\")    \n",
    "    away_dates_with_year = df_away['Date'].apply(\n",
    "        lambda x: f\"{x}/{year+1}\" if int(str(x).split('/')[0]) <= 6 \n",
    "        else f\"{x}/{year}\")\n",
    "\n",
    "    # Now convert to datetime\n",
    "    home_game_dates = pd.to_datetime(home_dates_with_year)\n",
    "    away_game_dates = pd.to_datetime(away_dates_with_year)\n",
    "\n",
    "    # Gets the result of the game\n",
    "    home_game_win = df_home['HomeWin'].to_list()\n",
    "    away_game_win = df_away['AwayWin'].to_list()\n",
    "\n",
    "    # Convert to \"Win\" or \"Loss\"\n",
    "    home_game_win = [\"Win\" if bool(x) else \"Loss\" for x in home_game_win]\n",
    "    away_game_win = [\"Win\" if bool(x) else \"Loss\" for x in away_game_win]\n",
    "\n",
    "    # Creates an away, home df, with the pairs for results and tags the Location\n",
    "    home = pd.DataFrame(list(zip(home_game_dates, home_game_win)))\n",
    "    away = pd.DataFrame(list(zip(away_game_dates, away_game_win)))\n",
    "    home[\"Location\"] = \"Home\"\n",
    "    away[\"Location\"] = \"Away\"\n",
    "\n",
    "    # Puts the two together and sorts them by date\n",
    "    season = pd.concat([home, away], ignore_index=True) \n",
    "    season.columns = [\"Date\", \"Result\", \"Location\"]\n",
    "    season = season.sort_values('Date').reset_index(drop=True)    \n",
    "\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ceccf-d89b-4e5a-8a89-02874fc7149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nba_game_date(team,year):\n",
    "    #first get teamId for this dataset\n",
    "    path_nba = kagglehub.dataset_download(\"eoinamoore/historical-nba-data-and-player-box-scores\")\n",
    "    team_df = pd.read_csv(f\"{path_nba}/TeamHistories.csv\")\n",
    "\n",
    "    #searches the dataset for the ID, returns nothing if not found\n",
    "    team_id = team_df[team_df['teamName'] == team]['teamId']\n",
    "    if not team_id.empty:\n",
    "        team_id = team_id.iloc[0]\n",
    "    else:\n",
    "        print(\"Team not found in dataset, look at the documentation.\")\n",
    "        return\n",
    "\n",
    "    #use team_id and year to sort games wanted\n",
    "    df = pd.read_csv(f\"{path_nba}/Games.csv\", low_memory=False)\n",
    "    df[\"gameDate\"] = pd.to_datetime(df[\"gameDate\"])\n",
    "    start = pd.to_datetime(f\"{year}-10-01\")\n",
    "    end = pd.to_datetime(f\"{year+1}-06-30\")\n",
    "    df_home = df[(df[\"hometeamId\"] == team_id) & ((df['gameDate'] >= start) & (df['gameDate'] <= end))]\n",
    "    df_away = df[(df[\"awayteamId\"] == team_id) & ((df['gameDate'] >= start) & (df['gameDate'] <= end))]\n",
    "\n",
    "\n",
    "    home_game_dates = df_home[\"gameDate\"].to_list()\n",
    "    away_game_dates = df_away[\"gameDate\"].to_list()\n",
    "    \n",
    "    home_game_win = [x == team_id for x in df_home['winner']]\n",
    "    away_game_win = [x == team_id for x in df_away['winner']]\n",
    "\n",
    "    #Creates an away, home df, with the pairs for results and tags the Location\n",
    "    home = pd.DataFrame(list(zip(home_game_dates, home_game_win)))\n",
    "    away = pd.DataFrame(list(zip(away_game_dates, away_game_win)))\n",
    "    home[\"Location\"] = \"Home\"\n",
    "    away[\"Location\"] = \"Away\"\n",
    "    season = pd.concat([home, away], ignore_index=True) \n",
    "    season.columns = [\"Date\", \"Result\", \"Location\"]\n",
    "    season = season.sort_values('Date').reset_index(drop=True)    \n",
    "    \n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738eb37-414c-4267-b5ef-fa4e5d8639a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_sixers_games(start_year=2021, end_year=2024):\n",
    "    \"\"\"\n",
    "    Load all 76ers NBA games across multiple years and add 'date' and 'year' columns.\n",
    "\n",
    "    Parameters:\n",
    "        start_year (int): Start year (inclusive)\n",
    "        end_year (int): End year (inclusive)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame of all games with 'date', 'year', and 'Location'\n",
    "    \"\"\"\n",
    "    all_games = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        games = nba_game_date(\"76ers\", year).copy()\n",
    "        games[\"date\"] = pd.to_datetime(games[\"Date\"]).dt.date\n",
    "        games[\"year\"] = year\n",
    "        all_games.append(games)\n",
    "    return pd.concat(all_games, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eae49a-813e-4d46-a981-e3342b1bc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_eagles_games(start_year=2017, end_year=2024):\n",
    "    \"\"\"\n",
    "    Load all Eagles NFL games across multiple years and add a clean 'date' and 'year' column.\n",
    "\n",
    "    Parameters:\n",
    "        start_year (int): Start year (inclusive)\n",
    "        end_year (int): End year (inclusive)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame of all games with 'date', 'year', and 'Location'\n",
    "    \"\"\"\n",
    "    all_games = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        games = nfl_game_date(year, \"Eagles\").copy()\n",
    "        games[\"date\"] = pd.to_datetime(games[\"Date\"]).dt.date\n",
    "        games[\"year\"] = year\n",
    "        all_games.append(games)\n",
    "    return pd.concat(all_games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702df83d-af1d-4135-8daf-0f3a92782b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_bears_games(start_year=2021, end_year=2024):\n",
    "    \"\"\"\n",
    "    Load all Bears NFL games across multiple years and add a clean 'date' and 'year' column.\n",
    "\n",
    "    Parameters:\n",
    "        start_year (int): Start year (inclusive)\n",
    "        end_year (int): End year (inclusive)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame of all games with 'date', 'year', and 'Location'\n",
    "    \"\"\"\n",
    "    all_games = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        games = nfl_game_date(year, \"Bears\").copy()\n",
    "        games[\"date\"] = pd.to_datetime(games[\"Date\"]).dt.date\n",
    "        games[\"year\"] = year\n",
    "        all_games.append(games)\n",
    "    return pd.concat(all_games, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a305c78-79bc-4873-8e2b-f78a8751650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_crime_data(df, stadium_coords, date_col,zip_shapes=None,lat_col='lat',lng_col='lng'):\n",
    "    \"\"\"\n",
    "    Preprocess crime data:\n",
    "    - Parses date column\n",
    "    - Converts to GeoDataFrame using lat/lng\n",
    "    - Computes distance to stadium\n",
    "    - Optionally joins ZIP code geometries\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw crime data with 'lat', 'lng', 'date' columns\n",
    "        stadium_coords (tuple): (longitude, latitude) of stadium\n",
    "        zip_shapes (gpd.GeoDataFrame, optional): ZIP code shapefile with 'geometry' and 'zip_code'\n",
    "    \n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Crime GeoDataFrame with distance and optional ZIP code\n",
    "    \"\"\"\n",
    "    # Clean and parse\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df['lat'] = pd.to_numeric(df[lat_col], errors='coerce')\n",
    "    df['lng'] = pd.to_numeric(df[lng_col], errors='coerce')\n",
    "    df = df.dropna(subset=['lat', 'lng', 'date'])\n",
    "\n",
    "    # Geo conversion\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['lng'], df['lat']), crs=\"EPSG:4326\")\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # Project stadium point\n",
    "    stadium_point = Point(stadium_coords)\n",
    "    stadium_proj = gpd.GeoSeries([stadium_point], crs=\"EPSG:4326\").to_crs(epsg=3857).iloc[0]\n",
    "\n",
    "    # Distance in meters\n",
    "    gdf['distance_to_stadium_m'] = gdf.geometry.distance(stadium_proj)\n",
    "\n",
    "    # Optional ZIP join\n",
    "    if zip_shapes is not None:\n",
    "        if 'zip' in zip_shapes.columns:\n",
    "            zip_shapes = zip_shapes.rename(columns={\"zip\": \"zip_code\"})\n",
    "        gdf = gpd.sjoin(gdf, zip_shapes[['geometry', 'zip_code']], how=\"left\", predicate=\"within\")\n",
    "\n",
    "    return gdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf393bd-4f77-4893-9bc8-1a92e8d72b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_game_windows(df, games_df, team_name=None, date_col='date'):\n",
    "    \"\"\"\n",
    "    Tag crimes that occur on the same day as a game (whole-day tagging).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Crime data with a datetime column (default 'date').\n",
    "        games_df (pd.DataFrame): Game schedule with 'Date' column (datetime).\n",
    "        team_name (str, optional): For labeling only.\n",
    "        date_col (str): Column in df to compare with game dates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original crime data with 'is_game_window' column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    games_df = games_df.copy()\n",
    "\n",
    "    # Validate and clean date column in crime data\n",
    "    if date_col not in df.columns:\n",
    "        raise ValueError(f\"'{date_col}' not found in crime DataFrame.\")\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.tz_localize(None)\n",
    "    df = df.dropna(subset=[date_col])\n",
    "\n",
    "    # Convert game times to dates\n",
    "    games_df['Date'] = pd.to_datetime(games_df['Date'], errors='coerce').dt.tz_localize(None)\n",
    "    games_df = games_df.dropna(subset=['Date'])\n",
    "    game_dates = set(games_df['Date'].dt.date)\n",
    "\n",
    "    # Tag entire day as game day\n",
    "    df['is_game_window'] = df[date_col].dt.date.isin(game_dates)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44484c8c-66e8-4595-a49b-d89b057a8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_crime_delta(\n",
    "    crime_df,\n",
    "    distance_col='distance_to_stadium_m',\n",
    "    is_game_col='is_game_window',\n",
    "    bin_size_m=1000,\n",
    "    max_dist_m=5000,\n",
    "    bins=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute change in average crime counts by distance band from the stadium.\n",
    "\n",
    "    Parameters:\n",
    "        crime_df (pd.DataFrame): Crime data with distance and game window indicators.\n",
    "        distance_col (str): Column name for distance from stadium in meters.\n",
    "        is_game_col (str): Boolean column indicating game-related crime windows.\n",
    "        bin_size_m (int): Width of distance bins in meters (used only if bins is None).\n",
    "        max_dist_m (int): Maximum distance to consider (used only if bins is None).\n",
    "        bins (list, optional): Custom list of bin edges in meters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Δ crime statistics per distance band.\n",
    "    \"\"\"\n",
    "    df = crime_df.copy()\n",
    "    df = df[df[distance_col].notnull()]\n",
    "\n",
    "    # Use custom bins if provided, otherwise generate default bins\n",
    "    if bins is None:\n",
    "        bins = list(np.arange(0, max_dist_m + bin_size_m, bin_size_m))\n",
    "    if bins[-1] != float('inf'):\n",
    "        bins.append(float('inf'))  # Add catch-all bin\n",
    "\n",
    "\n",
    "    # Create bin labels\n",
    "    labels = [f\"{int(bins[i]/1000)}–{int(bins[i+1]/1000)}km\" for i in range(len(bins)-2)]\n",
    "    labels.append(f\">{int(bins[-2]/1000)}km\")\n",
    "    df[\"distance_band_km\"] = pd.cut(df[distance_col], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    # Group by game window and distance band\n",
    "    grouped = df.groupby([is_game_col, \"distance_band_km\"]).size().reset_index(name=\"crime_count\")\n",
    "    \n",
    "    # Pivot table\n",
    "    pivot = grouped.pivot(index=\"distance_band_km\", columns=is_game_col, values=\"crime_count\").fillna(0)\n",
    "\n",
    "    # Standardize column names\n",
    "    if True in pivot.columns and False in pivot.columns:\n",
    "        pivot.columns = ['non_game_crime', 'game_crime']\n",
    "    elif True in pivot.columns:\n",
    "        pivot.columns = ['game_crime']\n",
    "        pivot['non_game_crime'] = 0\n",
    "    elif False in pivot.columns:\n",
    "        pivot.columns = ['non_game_crime']\n",
    "        pivot['game_crime'] = 0\n",
    "\n",
    "    # Normalize by number of days in each category\n",
    "    n_game_days = df[df[is_game_col]].date.dt.date.nunique()\n",
    "    n_non_game_days = df[~df[is_game_col]].date.dt.date.nunique()\n",
    "\n",
    "    if n_game_days == 0 or n_non_game_days == 0:\n",
    "        raise ValueError(\"No game or non-game days found — cannot compute delta.\")\n",
    "\n",
    "    # Compute averages and delta\n",
    "    pivot[\"avg_game_crime\"] = pivot[\"game_crime\"] / n_game_days\n",
    "    pivot[\"avg_non_game_crime\"] = pivot[\"non_game_crime\"] / n_non_game_days\n",
    "    pivot[\"delta_crime\"] = pivot[\"avg_game_crime\"] - pivot[\"avg_non_game_crime\"]\n",
    "    print(pivot)\n",
    "\n",
    "    return pivot.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebf09a-556d-4b65-b655-73bdd75291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stadium_radii_map_with_bar_chart(\n",
    "    stadium_coords,\n",
    "    crime_df,\n",
    "    delta_df,\n",
    "    radii_meters=[1000, 5000, 10000, 20000],\n",
    "    zoom=15,\n",
    "    title=\"Stadium Radius Map + Δ Crime by Distance Band\",\n",
    "    lat_col=\"lat\",\n",
    "    lng_col=\"lng\",\n",
    "    save_path_map=None,\n",
    "    save_path_bar=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a map with concentric radius bands around a stadium and a bar chart of precomputed Δ crimes.\n",
    "\n",
    "    Parameters:\n",
    "        stadium_coords (tuple): (longitude, latitude) of the stadium\n",
    "        crime_df (pd.DataFrame): Used only to show map region; must have lat/lng for mapbox to render\n",
    "        delta_df (pd.DataFrame): Precomputed Δ crime data with 'distance_band_km' and 'delta_crime'\n",
    "        radii_meters (list): Radii to draw on map\n",
    "        zoom (int): Map zoom level\n",
    "        title (str): Title of the map\n",
    "        lat_col (str): Name of column with latitude values\n",
    "        lng_col (str): Name of column with longitude values\n",
    "        save_path_map (str): Optional path to save the map figure\n",
    "        save_path_bar (str): Optional path to save the bar chart figure\n",
    "    \"\"\"\n",
    "    stadium_lon, stadium_lat = stadium_coords\n",
    "\n",
    "    # Create projection to handle buffer geometry\n",
    "    proj = pyproj.Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True).transform\n",
    "    inverse_proj = pyproj.Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\", always_xy=True).transform\n",
    "    point_proj = transform(proj, Point(stadium_lon, stadium_lat))\n",
    "\n",
    "    # Generate concentric rings for mapping\n",
    "    bands = []\n",
    "    for r in radii_meters:\n",
    "        buffer = transform(inverse_proj, point_proj.buffer(r))\n",
    "        bands.append(gpd.GeoDataFrame({'radius_m': [r]}, geometry=[buffer], crs=\"EPSG:4326\"))\n",
    "\n",
    "    # Initialize map\n",
    "    fig_map = go.Figure()\n",
    "    fig_map.update_layout(\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        mapbox_zoom=zoom,\n",
    "        mapbox_center={\"lat\": stadium_lat, \"lon\": stadium_lon},\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    # Draw radius bands\n",
    "    for gdf in bands:\n",
    "        geojson = gdf.__geo_interface__\n",
    "        radius = gdf['radius_m'].iloc[0]\n",
    "        fig_map.add_trace(go.Choroplethmapbox(\n",
    "            geojson=geojson,\n",
    "            locations=[0],\n",
    "            z=[radius],\n",
    "            colorscale='Blues',\n",
    "            showscale=False,\n",
    "            name=f\"{radius / 1000:.1f} km radius\",\n",
    "            marker_opacity=0.3,\n",
    "            marker_line_width=1\n",
    "        ))\n",
    "\n",
    "    # Stadium marker\n",
    "    fig_map.add_trace(go.Scattermapbox(\n",
    "        lat=[stadium_lat],\n",
    "        lon=[stadium_lon],\n",
    "        mode='markers+text',\n",
    "        marker=go.scattermapbox.Marker(size=10, color='red'),\n",
    "        text=[\"Stadium\"],\n",
    "        textposition=\"top right\"\n",
    "    ))\n",
    "\n",
    "    # Δ Crime Bar Chart\n",
    "    fig_bar = px.bar(\n",
    "        delta_df,\n",
    "        x=\"distance_band_km\",\n",
    "        y=\"delta_crime\",\n",
    "        title=\"Δ Crime per Day by Distance Band\",\n",
    "        labels={\n",
    "            \"distance_band_km\": \"Distance Band (km)\",\n",
    "            \"delta_crime\": \"Δ Crimes per Day (Game - Non-game)\"\n",
    "        },\n",
    "        text_auto=True\n",
    "    )\n",
    "\n",
    "    # Save figures if paths are provided\n",
    "    if save_path_map:\n",
    "        fig_map.write_image(save_path_map)\n",
    "    if save_path_bar:\n",
    "        fig_bar.write_image(save_path_bar)\n",
    "\n",
    "    # Display\n",
    "    fig_map.show()\n",
    "    fig_bar.show()\n",
    "    return fig_map, fig_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e0e07-9557-4870-b34c-f99167282fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def compute_event_and_followup_crime_delta(\n",
    "    crime_df, \n",
    "    event_date, \n",
    "    date_col='date',\n",
    "    return_fig=True  # Optional flag to control chart output\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute and visualize crime delta on an event day and the day after,\n",
    "    compared to the average daily crime in the prior year.\n",
    "\n",
    "    Returns:\n",
    "        dict: Statistics summary\n",
    "        fig (optional): Plotly bar chart\n",
    "    \"\"\"\n",
    "    # Ensure dates are tz-naive\n",
    "    event_date = pd.to_datetime(event_date).tz_localize(None)\n",
    "    next_day = event_date + pd.Timedelta(days=1)\n",
    "\n",
    "    df = crime_df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col]).dt.tz_localize(None)\n",
    "\n",
    "    one_year_prior = event_date - pd.Timedelta(days=365)\n",
    "\n",
    "    # Filter data\n",
    "    crimes_event_day = df[df[date_col] == event_date]\n",
    "    crimes_next_day = df[df[date_col] == next_day]\n",
    "    prior_year_crimes = df[\n",
    "        (df[date_col] >= one_year_prior) &\n",
    "        (df[date_col] < event_date)\n",
    "    ]\n",
    "\n",
    "    avg_crimes_per_day = prior_year_crimes.groupby(date_col).size().mean()\n",
    "\n",
    "    # Stats\n",
    "    event_crimes = len(crimes_event_day)\n",
    "    next_crimes = len(crimes_next_day)\n",
    "    delta_event = event_crimes - avg_crimes_per_day\n",
    "    delta_next = next_crimes - avg_crimes_per_day\n",
    "\n",
    "    summary = {\n",
    "        \"event_date\": event_date.date(),\n",
    "        \"next_day\": next_day.date(),\n",
    "        \"event_day_crimes\": event_crimes,\n",
    "        \"next_day_crimes\": next_crimes,\n",
    "        \"average_crimes_per_day\": round(avg_crimes_per_day, 2),\n",
    "        \"delta_event_day\": round(delta_event, 2),\n",
    "        \"delta_next_day\": round(delta_next, 2)\n",
    "    }\n",
    "\n",
    "    if not return_fig:\n",
    "        return summary\n",
    "\n",
    "    # Create bar chart\n",
    "    bar_data = pd.DataFrame({\n",
    "        \"Day Type\": [\"Event Day\", \"Next Day\", \"Average (Past Year)\"],\n",
    "        \"Crimes\": [event_crimes, next_crimes, avg_crimes_per_day]\n",
    "    })\n",
    "\n",
    "    fig = px.bar(\n",
    "        bar_data,\n",
    "        x=\"Day Type\",\n",
    "        y=\"Crimes\",\n",
    "        color=\"Day Type\",\n",
    "        text=\"Crimes\",\n",
    "        title=f\"Crime Counts on Event & Next Day vs. Baseline ({event_date.date()})\"\n",
    "    )\n",
    "    fig.add_hline(\n",
    "        y=avg_crimes_per_day,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"gray\",\n",
    "        annotation_text=\"Avg. Daily Crime (Past Year)\",\n",
    "        annotation_position=\"top left\"\n",
    "    )\n",
    "    fig.update_layout(yaxis_title=\"Crime Count\")\n",
    "\n",
    "    return summary, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d5c51-11cb-410a-b56e-3ed16cf4cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_comparison_map(\n",
    "    crime_df,\n",
    "    event1_date,\n",
    "    event2_date,\n",
    "    event1_label=\"Event 1\",\n",
    "    event2_label=\"Event 2\",\n",
    "    lat_col=\"lat\",\n",
    "    lng_col=\"lng\",\n",
    "    date_col=\"date\",\n",
    "    crime_type_col=\"Primary Type\",\n",
    "    zoom=11,\n",
    "    title=\"Crime Locations on Key Event Days\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a side-by-side map of crimes on two specified dates using lat/lng data.\n",
    "\n",
    "    Parameters:\n",
    "        crime_df (pd.DataFrame): Full crime dataset with coordinates and a datetime column.\n",
    "        event1_date (str or datetime): First date (e.g. \"2025-02-09\").\n",
    "        event2_date (str or datetime): Second date (e.g. \"2025-02-10\").\n",
    "        event1_label (str): Label to show for first event.\n",
    "        event2_label (str): Label to show for second event.\n",
    "        lat_col (str): Name of the latitude column.\n",
    "        lng_col (str): Name of the longitude column.\n",
    "        date_col (str): Name of the date column.\n",
    "        crime_type_col (str): Optional column to show in hover.\n",
    "        zoom (int): Map zoom level.\n",
    "        title (str): Title of the map.\n",
    "    \"\"\"\n",
    "    df = crime_df.copy()\n",
    "    df[lat_col] = pd.to_numeric(df[lat_col], errors=\"coerce\")\n",
    "    df[lng_col] = pd.to_numeric(df[lng_col], errors=\"coerce\")\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "\n",
    "    # Ensure date inputs are datetime\n",
    "    event1_date = pd.to_datetime(event1_date)\n",
    "    event2_date = pd.to_datetime(event2_date)\n",
    "\n",
    "    # Debug: Check for timezone mismatch\n",
    "    if df[date_col].dt.tz is not None:\n",
    "        event1_date = event1_date.tz_localize(\"UTC\")\n",
    "        event2_date = event2_date.tz_localize(\"UTC\")\n",
    "\n",
    "    # Filter and drop missing coordinates\n",
    "    df_event1 = df[df[date_col] == event1_date].dropna(subset=[lat_col, lng_col]).copy()\n",
    "    df_event2 = df[df[date_col] == event2_date].dropna(subset=[lat_col, lng_col]).copy()\n",
    "\n",
    "    df_event1[\"Event\"] = event1_label\n",
    "    df_event2[\"Event\"] = event2_label\n",
    "    combined = pd.concat([df_event1, df_event2], axis=0)\n",
    "\n",
    "    # Plot\n",
    "    fig = px.scatter_mapbox(\n",
    "        combined,\n",
    "        lat=lat_col,\n",
    "        lon=lng_col,\n",
    "        color=\"Event\",\n",
    "        hover_name=crime_type_col if crime_type_col in combined.columns else None,\n",
    "        hover_data=[date_col] if date_col in combined.columns else None,\n",
    "        zoom=zoom,\n",
    "        height=600,\n",
    "        title=title\n",
    "    )\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 40, \"l\": 0, \"b\": 0})\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d86d0-ccc6-4a94-b6e6-0a899827aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_game_day_crime_boxplot(crime_counts, result_col=\"Result\", title=\"Crime Counts on Game Days by Win/Loss\"):\n",
    "    \"\"\"\n",
    "    Generate a box plot comparing crime counts on game days by win/loss result.\n",
    "\n",
    "    Parameters:\n",
    "        crime_counts (pd.DataFrame): DataFrame with columns ['date', result_col, 'crime_count'].\n",
    "        result_col (str): Column name indicating game result (default is \"Result\").\n",
    "        title (str): Title for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None (displays plot)\n",
    "    \"\"\"\n",
    "    fig = px.box(\n",
    "        crime_counts,\n",
    "        x=result_col,\n",
    "        y=\"crime_count\",\n",
    "        points=\"all\",\n",
    "        title=title\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3828bac-e250-4dbe-9897-df2957368d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def welchs_t_test_by_result(crime_counts, result_col=\"Result\", group1=\"Win\", group2=\"Loss\"):\n",
    "    \"\"\"\n",
    "    Run Welch's t-test comparing crime counts for two game outcomes.\n",
    "\n",
    "    Parameters:\n",
    "        crime_counts (pd.DataFrame): DataFrame with columns ['date', result_col, 'crime_count'].\n",
    "        result_col (str): Name of the result column (e.g., \"Result\").\n",
    "        group1 (str): Label for first result group (default \"Win\").\n",
    "        group2 (str): Label for second result group (default \"Loss\").\n",
    "\n",
    "    Returns:\n",
    "        tuple: (t_statistic, p_value)\n",
    "    \"\"\"\n",
    "    group1_vals = crime_counts[crime_counts[result_col] == group1][\"crime_count\"]\n",
    "    group2_vals = crime_counts[crime_counts[result_col] == group2][\"crime_count\"]\n",
    "\n",
    "    t_stat, p_val = ttest_ind(group1_vals, group2_vals, equal_var=False)\n",
    "    print(f\"Welch's t-test ({group1} vs {group2}): t={t_stat:.2f}, p={p_val:.4f}\")\n",
    "    return t_stat, p_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733fb9a-b9b2-4154-b819-8abe6a4af277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qss20]",
   "language": "python",
   "name": "conda-env-qss20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
